---
tags: ['LessWrong', 'Portal', 'Concept']
src: https://www.lesswrong.com/tag/really-powerful-optimization-process
---

The term [artificial intelligence](https://www.lesswrong.com/tag/artificial-general-intelligence) can have [anthropomorphic](https://www.lesswrong.com/tag/anthropomorphism) connotations. In some contexts, it might be useful to speak of a really powerful optimization process rather than a *superintelligence*. An AI that was nonanthropomorphic and nonsentient could theoretically still be a very powerful device that could drastically affect the future in precise ways.

## Blog posts
- [Dreams of Friendliness](http://lesswrong.com/lw/tj/dreams_of_friendliness/)
- [Aiming at the Target](http://lesswrong.com/lw/v9/aiming_at_the_target/)
- [Efficient Cross-Domain Optimization](http://lesswrong.com/lw/vb/efficient_crossdomain_optimization/)
- [Nonsentient Optimizers](http://lesswrong.com/lw/x5/nonsentient_optimizers/)
- [The Design Space of Minds-in-General](http://lesswrong.com/lw/rm/the_design_space_of_mindsingeneral/)

## 
- [Creature or Technology](http://www.acceleratingfuture.com/steven/?p=227)
-  by 
- [Steven Kaas](https://www.lesswrong.com/tag/steven-kaas)
- [The Stamp Collecting Device](http://intelligence.org/blog/2007/06/11/the-stamp-collecting-device/)
-  by Nick Hay

## See also
- [Optimization process](https://www.lesswrong.com/tag/optimization)
- , 
- [configuration space](https://www.lesswrong.com/tag/configuration-space)
- [Artificial general intelligence](https://www.lesswrong.com/tag/artificial-general-intelligence)
- , 
- [singleton](https://www.lesswrong.com/tag/singleton)
- [Friendly Artificial Intelligence](https://www.lesswrong.com/tag/friendly-artificial-intelligence)
- [Anthropomorphism](https://www.lesswrong.com/tag/anthropomorphism)
- , 
- [alien values](https://www.lesswrong.com/tag/alien-values)
- [Evolution as alien god](https://www.lesswrong.com/tag/evolution-as-alien-god)
- [Complexity of value](https://www.lesswrong.com/tag/complexity-of-value)



---

